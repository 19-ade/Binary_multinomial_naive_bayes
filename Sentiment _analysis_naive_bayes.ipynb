{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count":0,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "df = pd.read_csv('Umich_sentiment_analysis_randomized.txt', sep='\\t',\n",
        "                 names=['sentiment', 'document'])\n",
        "\n",
        "df.head(10)\n"
      ],
      "execution_count":0,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>sentiment<\/th>\n",
              "      <th>document<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0<\/th>\n",
              "      <td>0<\/td>\n",
              "      <td>Not because I hate Harry Potter, but because I...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>1<\/th>\n",
              "      <td>0<\/td>\n",
              "      <td>Is it just me, or does Harry Potter suck?...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>2<\/th>\n",
              "      <td>1<\/td>\n",
              "      <td>Brokeback Mountain had a beautiful score, and ...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>3<\/th>\n",
              "      <td>1<\/td>\n",
              "      <td>i love being a sentry for mission impossible a...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>4<\/th>\n",
              "      <td>0<\/td>\n",
              "      <td>Harry Potter dragged Draco Malfoy â€™ s trousers...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>5<\/th>\n",
              "      <td>1<\/td>\n",
              "      <td>Anyway, thats why I love \" Brokeback Mountain.<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>6<\/th>\n",
              "      <td>0<\/td>\n",
              "      <td>These Harry Potter movies really suck.<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>7<\/th>\n",
              "      <td>1<\/td>\n",
              "      <td>the last stand and Mission Impossible 3 both w...<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>8<\/th>\n",
              "      <td>1<\/td>\n",
              "      <td>I love Brokeback Mountain....<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>9<\/th>\n",
              "      <td>1<\/td>\n",
              "      <td>I love Harry Potter.<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "length = len(df)  # length of the datframe\n",
        "pos_count = len(df[df['sentiment'] == 1])  # positive_sentiment count\n",
        "neg_count = len(df[df['sentiment'] == 0])  # negative_sentiment count\n",
        "print (\n",
        "    'length=',\n",
        "    length,\n",
        "    '\\npos_count',\n",
        "    pos_count,\n",
        "    '\\nneg_count',\n",
        "    neg_count,\n",
        "    )"
      ],
      "execution_count":0,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "length= 6725 \n",
            "pos_count 3804 \n",
            "neg_count 2921\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "sns.countplot(y=\"sentiment\",data=df)#plotting the data\n",
        "plt.show()"
      ],
      "execution_count":0,
      "outputs":[
        {
          "data":{
            "image\/png":[
              "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\n"
            ]
          },
          "metadata":{
            "image\/png":{
              "width":0,
              "height":0
            }
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "**sentence_to_words()**:here we first convert the sentence to lowercase. Then we use .split() to split it into different words. We iterate over the letters of the word to pinpoint which are alphabets and which are not. \n",
        "\n",
        "**bag_of_words_maker()**: This function takes in the document and the class for each document and converts it into the _bag of words_ format . We folloed the binary multinomial NB , so the repition of words in the document was not noted. We place more weight on the fact whether the word is present or not rather than no of times it appeared. I tried to implement a rudimentary stop_word list to the selected words. This function returns the length of the positive class and the negative sentiment class along with the bag of words in a dataframe form . It lists the number of times each word has been repeated in the positive and negative sentiment class respectively.\n",
        "\n",
        "**naive_bias_train()**: here we send the document and class series respectively . It calculates the prior probability of each class\n",
        "{ P(C<sub>neg<\/sub>),P(C<sub>pos<\/sub>) } and it claculates the P(w<sub>i<\/sub>\/C) using the formula :\n",
        "\n",
        " P(w<sub>i<\/sub>\/C)=count(w<sub>i<\/sub>,c)+a\/x+V*a , where a is the laplace smoothing function, x is the length of the class c and V is the total vocabulary(total length of the bag_of_words)\n",
        "\n",
        "It returns the prior probability of both classes(in this case positive and negative) and the dataframe containing the likelihood probability of each word.\n",
        "\n",
        "\n",
        "**naive_bias_predict()**: Now we finally predict the given test case. We loop over the number of documents present in the test dataframe. looping over the total length of bag we find if the words of the given document is present in the bag or not . If True we multiply the likelihood probability for both positive and negative class. Finally we multiply the prior probability of the respective classes to the likelihood and decide for which class the probability is max. Essentially this step:\n",
        "\n",
        "C<sub>nb<\/sub>=argmax<sub>câˆˆC<\/sub> P(w<sub>i<\/sub>\/c)*P(c)\n",
        "\n",
        "It returns the list of predicted classes."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\n",
        "\n",
        "\n",
        "def sentence_to_words(sentence):\n",
        "\n",
        "    l = sentence.lower()  # convert sentence to lowercase\n",
        "    l = l.split()  # split sentence into individual word\n",
        "    p = ''\n",
        "    word_list = []\n",
        "\n",
        "    for word in l:\n",
        "\n",
        "        p = ''\n",
        "\n",
        "        for letter in word:\n",
        "\n",
        "            if ord(letter) >= 67 and ord(letter) <= 122:\n",
        "                p = p + letter\n",
        "        word_list.append(p)\n",
        "\n",
        "    return word_list  # return the word list of the sentence devoid of special characters and numericals\n",
        "\n",
        "\n",
        "def naive_bayes_train(X, Y, a=0.000001):\n",
        "    n_length = len(X)\n",
        "    n_class_pos = len(Y[Y == 1])\n",
        "    n_class_neg = len(Y[Y == 0])\n",
        "    prior_pos = n_class_pos \/ n_length  # prior probability for  class\n",
        "    prior_neg = n_class_neg \/ n_length\n",
        "    (n, p, bag) = bag_of_words_maker(X, Y)\n",
        "\n",
        "    pr = {}\n",
        "\n",
        "    for i in range(len(bag)):\n",
        "        p_pos = (bag['count_pos'][i] + a) \/ (p + len(bag) * a)\n",
        "\n",
        "        p_neg = (bag['count_neg'][i] + a) \/ (n + len(bag) * a)\n",
        "\n",
        "        pr[bag['index'][i]] = [p_pos, p_neg]\n",
        "    pr = pd.DataFrame(pr).T\n",
        "    pr.columns = ['sent=positive', 'sent=negative']\n",
        "    pr = pr.reset_index()\n",
        "\n",
        "    return (prior_pos, prior_neg, pr)\n",
        "\n",
        "\n",
        "def naive_bayes_predict(\n",
        "    X,\n",
        "    pr,\n",
        "    prior_pos,\n",
        "    prior_neg,\n",
        "    ):\n",
        "    Y = []\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        k_pos = 1\n",
        "        k_neg = 1\n",
        "        p = sentence_to_words(X[i])\n",
        "\n",
        "        for k in range(len(pr)):\n",
        "\n",
        "            for word in p:\n",
        "\n",
        "                if word == pr['index'][k]:\n",
        "                    k_pos = k_pos * pr['sent=positive'][k]\n",
        "                    k_neg = k_neg * pr['sent=negative'][k]\n",
        "\n",
        "        nb = [prior_neg * k_neg, prior_pos * k_pos]\n",
        "        Y.append(np.argmax(nb))\n",
        "\n",
        "    return Y\n",
        "\n",
        "\n",
        "def bag_of_words_maker(X, Y):\n",
        "\n",
        "    bag_dict_binary_NB_pos = {}\n",
        "    bag_dict_binary_NB_neg = {}\n",
        "    stop_words = [\n",
        "        'the',\n",
        "        'da',\n",
        "        'vinci',\n",
        "        'is',\n",
        "        'a',\n",
        "        'was',\n",
        "        'it',\n",
        "        'brokeback',\n",
        "        'mountain',\n",
        "        'code',\n",
        "        'and',\n",
        "        '',\n",
        "        'harry',\n",
        "        'potter',\n",
        "        'i',\n",
        "        'am',\n",
        "        'of',\n",
        "        'that',\n",
        "        ]\n",
        "    for i in range(len(X)):\n",
        "        p = sentence_to_words(X[i])\n",
        "        sent = Y[i]\n",
        "        x_pos = {}\n",
        "        x_neg = {}\n",
        "\n",
        "        if sent == 1:\n",
        "            for word in p:\n",
        "\n",
        "                if word in x_pos.keys():\n",
        "                    x_pos[word] = [x_pos[word][0] + 1, x_pos[word][1]]\n",
        "                else:\n",
        "                    x_pos[word] = [1, sent]\n",
        "\n",
        "            for key in x_pos.keys():\n",
        "\n",
        "                if key in bag_dict_binary_NB_pos.keys():\n",
        "                    bag_dict_binary_NB_pos[key] = \\\n",
        "                        [bag_dict_binary_NB_pos[key][0] + 1,\n",
        "                         bag_dict_binary_NB_pos[key][1]]\n",
        "                else:\n",
        "\n",
        "                    bag_dict_binary_NB_pos[key] = [1, sent]\n",
        "\n",
        "        if sent == 0:\n",
        "\n",
        "            for word in p:\n",
        "                if word in x_neg.keys():\n",
        "                    x_neg[word] = [x_neg[word][0] + 1, x_neg[word][1]]\n",
        "                else:\n",
        "                    x_neg[word] = [1, sent]\n",
        "            for key in x_neg.keys():\n",
        "                if key in bag_dict_binary_NB_neg.keys():\n",
        "                    bag_dict_binary_NB_neg[key] = \\\n",
        "                        [bag_dict_binary_NB_neg[key][0] + 1,\n",
        "                         bag_dict_binary_NB_neg[key][1]]\n",
        "                else:\n",
        "\n",
        "                    bag_dict_binary_NB_neg[key] = [1, sent]\n",
        "\n",
        "    # print(bag_dict_multi.keys())\n",
        "\n",
        "    neg_bag = pd.DataFrame(bag_dict_binary_NB_neg).T\n",
        "    pos_bag = pd.DataFrame(bag_dict_binary_NB_pos).T\n",
        "\n",
        "    neg_bag.columns = ['count_neg', 'sentiment_neg']\n",
        "    pos_bag.columns = ['count_pos', 'sentiment_pos']\n",
        "    neg_bag = neg_bag.drop(stop_words)\n",
        "    pos_bag = pos_bag.drop(stop_words)\n",
        "    neg_bag = neg_bag.reset_index()\n",
        "    pos_bag = pos_bag.reset_index()\n",
        "    n = len(neg_bag)\n",
        "    p = len(pos_bag)\n",
        "    bag_of_words = pd.merge(neg_bag, pos_bag, on=['index'], how='outer')\n",
        "    bag_of_words['count_neg'] = bag_of_words['count_neg'].fillna(0)\n",
        "    bag_of_words['count_pos'] = bag_of_words['count_pos'].fillna(0)\n",
        "    bag_of_words['sentiment_neg'] = bag_of_words['sentiment_neg'\n",
        "            ].fillna(0)\n",
        "    bag_of_words['sentiment_pos'] = bag_of_words['sentiment_pos'\n",
        "            ].fillna(1)\n",
        "\n",
        "    return (n, p, bag_of_words)"
      ],
      "execution_count":0,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Heres an example to show how the functions work. Here we send the x and y containing the document and sentiment of the given dataset. bag_of_words_maker returns the length of the positive and negative classes and the binary count for each word in each class. "
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "x = df['document']\n",
        "y = df['sentiment']\n",
        "(n, p, bag_of_words) = bag_of_words_maker(x, y)\n",
        "print (n, ' ', p)\n",
        "bag_of_words.head(5)"
      ],
      "execution_count":0,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "1460   1373\n"
          ],
          "output_type":"stream"
        },
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>index<\/th>\n",
              "      <th>count_neg<\/th>\n",
              "      <th>sentiment_neg<\/th>\n",
              "      <th>count_pos<\/th>\n",
              "      <th>sentiment_pos<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0<\/th>\n",
              "      <td>not<\/td>\n",
              "      <td>166.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>25.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>1<\/th>\n",
              "      <td>because<\/td>\n",
              "      <td>180.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>327.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>2<\/th>\n",
              "      <td>hate<\/td>\n",
              "      <td>533.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>12.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>3<\/th>\n",
              "      <td>but<\/td>\n",
              "      <td>141.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>138.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>4<\/th>\n",
              "      <td>type<\/td>\n",
              "      <td>75.0<\/td>\n",
              "      <td>0.0<\/td>\n",
              "      <td>4.0<\/td>\n",
              "      <td>1.0<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "This function will return the prior probabilities of each class along with the likeliood probability of each word given a class ."
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "prior_pos,prior_neg,table = naive_bayes_train(x,y)\n",
        "table.head(5)"
      ],
      "execution_count":0,
      "outputs":[
        {
          "data":{
            "text\/html":[
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "<\/style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th><\/th>\n",
              "      <th>index<\/th>\n",
              "      <th>sent=positive<\/th>\n",
              "      <th>sent=negative<\/th>\n",
              "    <\/tr>\n",
              "  <\/thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0<\/th>\n",
              "      <td>not<\/td>\n",
              "      <td>0.018208<\/td>\n",
              "      <td>0.113698<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>1<\/th>\n",
              "      <td>because<\/td>\n",
              "      <td>0.238164<\/td>\n",
              "      <td>0.123287<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>2<\/th>\n",
              "      <td>hate<\/td>\n",
              "      <td>0.008740<\/td>\n",
              "      <td>0.365068<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>3<\/th>\n",
              "      <td>but<\/td>\n",
              "      <td>0.100510<\/td>\n",
              "      <td>0.096575<\/td>\n",
              "    <\/tr>\n",
              "    <tr>\n",
              "      <th>4<\/th>\n",
              "      <td>type<\/td>\n",
              "      <td>0.002913<\/td>\n",
              "      <td>0.051370<\/td>\n",
              "    <\/tr>\n",
              "  <\/tbody>\n",
              "<\/table>\n",
              "<\/div>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[\"document\"]\n",
        "Y = df[\"sentiment\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,)\n",
        "\n",
        "x_train = x_train.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "x_test = x_test.reset_index(drop=True)\n",
        "a,b,bag = naive_bayes_train(x_train,y_train)\n",
        "y_predicted = naive_bayes_predict(x_test,bag,a,b)\n",
        "y_predicted"
      ],
      "execution_count":0,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " ...]"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "print ('Accuracy=', accuracy_score(y_test, np.array(y_predicted)))\n",
        "\n",
        "(tn, fp, fn, tp) = confusion_matrix(y_test,\n",
        "                                    np.array(y_predicted)).ravel()\n",
        "\n",
        "print ('precsion=', tp \/ (tp + fp))\n",
        "print ('recall=', tp \/ (tp + fn))"
      ],
      "execution_count":0,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Accuracy= 0.9720570749108205\n",
            "precsion= 0.9807073954983923\n",
            "recall= 0.9692796610169492\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}